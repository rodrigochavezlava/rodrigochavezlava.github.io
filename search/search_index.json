{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"Documentaci%C3%B3n/Archivos-de-configuraci%C3%B3n/docker-compose/","text":"Docker-Compose.yml \u00b6 El archivo docker-compose.yml contiene la configuraci\u00f3n de varios servicios que forman parte del sistema. Para facilitar la comprensi\u00f3n, explicaremos cada servicio por separado. Comenzando con el servicio de Elasticsearch: Es importante destacar que todos los servicios utilizan la misma versi\u00f3n, en este caso la 7.15.2. Es crucial tener la misma versi\u00f3n en un sistema con servicios interconectados para evitar incompatibilidades y fallos de seguridad. services : elasticsearch : image : docker.elastic.co/elasticsearch/elasticsearch:7.15.2 Dentro del archivo de Docker Compose, el servicio de Elasticsearch es fundamental ya que todos los dem\u00e1s servicios dependen de \u00e9l. Si Elasticsearch falla, todos los servicios que dependen de \u00e9l dejar\u00e1n de funcionar. Por esta raz\u00f3n, se verifica constantemente si Elasticsearch est\u00e1 operativo. En caso de detectar un fallo, los dem\u00e1s servicios se detendr\u00e1n y esperar\u00e1n a que Elasticsearch se recupere. La configuraci\u00f3n de Elasticsearch es m\u00e1s precisa que la de otros servicios. depends_on : - elasticsearch En este caso, se encuentra en el modo \"single-node\", lo que significa que no hay m\u00e1s nodos y Elasticsearch funciona de forma independiente y segura. - \"discovery.type=single-node\" # Tipo de descubrimiento para Elasticsearch Pasando al servicio de Kibana: Este servicio es m\u00e1s independiente y no afecta directamente a los dem\u00e1s servicios. Si solo se produce un fallo en Kibana, los dem\u00e1s servicios seguir\u00e1n funcionando normalmente. Kibana utiliza el puerto predeterminado y se conecta a Elasticsearch para recibir informaci\u00f3n y datos. environment : ELASTICSEARCH_URL : <http://elasticsearch:9200> # URL de Elasticsearch En cuanto al servicio de Filebeat: Este servicio es un emisor que centraliza los logs de diferentes ubicaciones. Es importante resaltar que se configura con permisos de solo lectura (:ro) para mayor seguridad. Al no requerir escritura, se reduce un punto de vulnerabilidad en el sistema - ./filebeat.yml:/usr/share/filebeat/filebeat.yml:ro El servicio de Logstash: se encarga de procesar y enriquecer los datos de los eventos antes de enviarlos a Elasticsearch. Realiza tareas como la conversi\u00f3n y eliminaci\u00f3n de datos cr\u00edticos o sensibles. Logstash utiliza su puerto por defecto y tambi\u00e9n depende de Elasticsearch para enviar los datos procesados.. Por otro lado, el servicio de Suricata es una herramienta de detecci\u00f3n de amenazas y prevenci\u00f3n de intrusiones en red. Su configuraci\u00f3n es ligeramente diferente, ya que vigila constantemente la red y requiere algunas configuraciones adicionales. Tambi\u00e9n se configura como de solo lectura (:ro) debido a que es un sistema de eventos en tiempo real. Vigila las amenazas y detecta cualquier actividad maliciosa para minimizar el da\u00f1o posible. Se especifica la interfaz a la que Suricata estar\u00e1 atento y se pueden configurar diferentes opciones seg\u00fan las necesidades. Finalmente, el archivo de Docker Compose tambi\u00e9n incluye la versi\u00f3n del mismo y los vol\u00famenes necesarios para almacenar los datos de Elasticsearch - ./suricata.yaml:/etc/suricata/suricata.yaml:ro # Archivo de configuraci\u00f3n de Suricata network_mode : \"host\" command : -c /etc/suricata/suricata.yaml -i eth0 # Comando para ejecutar Suricata Tambi\u00e9n hay que especificar la interfaz que vigila y se puede especificar con distitnas opciones. version : '3.7' # Versi\u00f3n de la sintaxis del archivo docker-compose services : elasticsearch : # Servicio de Elasticsearch image : docker.elastic.co/elasticsearch/elasticsearch:7.15.2 # Imagen utilizada para el contenedor container_name : elasticsearch # Nombre del contenedor environment : - node.name=elasticsearch # Configuraci\u00f3n del nombre del nodo Elasticsearch - cluster.name=es-docker-cluster # Configuraci\u00f3n del nombre del cl\u00faster Elasticsearch - bootstrap.memory_lock=true # Configuraci\u00f3n para bloquear la memoria - \"ES_JAVA_OPTS=-Xms512m -Xmx512m\" # Opciones de configuraci\u00f3n para la memoria de Elasticsearch - \"discovery.type=single-node\" # Configuraci\u00f3n del tipo de descubrimiento del nodo Elasticsearch - \"xpack.security.enabled=false\" # Configuraci\u00f3n para deshabilitar la seguridad de X-Pack ulimits : memlock : soft : -1 # L\u00edmite blando para bloqueo de memoria hard : -1 # L\u00edmite duro para bloqueo de memoria volumes : - esdata:/usr/share/elasticsearch/data # Volumen utilizado para almacenar los datos de Elasticsearch ports : - 9200:9200 # Mapeo del puerto del contenedor al puerto del host kibana : # Servicio de Kibana image : docker.elastic.co/kibana/kibana:7.15.2 # Imagen utilizada para el contenedor container_name : kibana # Nombre del contenedor ports : - 5601:5601 # Mapeo del puerto del contenedor al puerto del host environment : ELASTICSEARCH_URL : http://elasticsearch:9200/ # URL de Elasticsearch volumes : - ./kibana.yml:/usr/share/kibana/config/kibana.yml # Volumen utilizado para la configuraci\u00f3n de Kibana depends_on : - elasticsearch # Dependencia del servicio de Elasticsearch filebeat : # Servicio de Filebeat image : docker.elastic.co/beats/filebeat:7.15.2 # Imagen utilizada para el contenedor container_name : filebeat # Nombre del contenedor user : root volumes : - ./filebeat.yml:/usr/share/filebeat/filebeat.yml:ro # Volumen utilizado para la configuraci\u00f3n de Filebeat - /var/log:/var/log:ro # Mapeo del directorio de logs del host al contenedor depends_on : - elasticsearch # Dependencia del servicio de Elasticsearch logstash : # Servicio de Logstash image : docker.elastic.co/logstash/logstash:7.15.2 # Imagen utilizada para el contenedor container_name : logstash # Nombre del contenedor volumes : - ./logstash.conf:/usr/share/logstash/pipeline/logstash.conf:ro # Volumen utilizado para la configuraci\u00f3n de Logstash ports : - 5044:5044 # Mapeo del puerto del contenedor al puerto del host depends_on : - elasticsearch # Dependencia del servicio de Elasticsearch suricata : # Servicio de Suricata image : jasonish/suricata:latest # Imagen utilizada para el contenedor user : root privileged : true volumes : - /var/log/suricata:/var/log/suricata # Mapeo del directorio de logs del host al contenedor - ./suricata.yaml:/etc/suricata/suricata.yaml:ro # Volumen utilizado para la configuraci\u00f3n de Suricata - /var/lib/suricata/rules:/var/lib/suricata/rules # Mapeo del directorio de reglas del host al contenedor - /etc/suricata/classification.config:/etc/suricata/classification.config # Mapeo del archivo de clasificaci\u00f3n del host al contenedor network_mode : \"host\" # Modo de red utilizado (comparte la red del host) command : -c /etc/suricata/suricata.yaml -i enp0s3 # Comando a ejecutar dentro del contenedor de Suricata volumes : esdata : driver : local # Tipo de driver de volumen utilizado (local) networks : default : external : name : encriptadisimo # Nombre de la red externa utilizada","title":"Docker-Compose.yml"},{"location":"Documentaci%C3%B3n/Archivos-de-configuraci%C3%B3n/docker-compose/#docker-composeyml","text":"El archivo docker-compose.yml contiene la configuraci\u00f3n de varios servicios que forman parte del sistema. Para facilitar la comprensi\u00f3n, explicaremos cada servicio por separado. Comenzando con el servicio de Elasticsearch: Es importante destacar que todos los servicios utilizan la misma versi\u00f3n, en este caso la 7.15.2. Es crucial tener la misma versi\u00f3n en un sistema con servicios interconectados para evitar incompatibilidades y fallos de seguridad. services : elasticsearch : image : docker.elastic.co/elasticsearch/elasticsearch:7.15.2 Dentro del archivo de Docker Compose, el servicio de Elasticsearch es fundamental ya que todos los dem\u00e1s servicios dependen de \u00e9l. Si Elasticsearch falla, todos los servicios que dependen de \u00e9l dejar\u00e1n de funcionar. Por esta raz\u00f3n, se verifica constantemente si Elasticsearch est\u00e1 operativo. En caso de detectar un fallo, los dem\u00e1s servicios se detendr\u00e1n y esperar\u00e1n a que Elasticsearch se recupere. La configuraci\u00f3n de Elasticsearch es m\u00e1s precisa que la de otros servicios. depends_on : - elasticsearch En este caso, se encuentra en el modo \"single-node\", lo que significa que no hay m\u00e1s nodos y Elasticsearch funciona de forma independiente y segura. - \"discovery.type=single-node\" # Tipo de descubrimiento para Elasticsearch Pasando al servicio de Kibana: Este servicio es m\u00e1s independiente y no afecta directamente a los dem\u00e1s servicios. Si solo se produce un fallo en Kibana, los dem\u00e1s servicios seguir\u00e1n funcionando normalmente. Kibana utiliza el puerto predeterminado y se conecta a Elasticsearch para recibir informaci\u00f3n y datos. environment : ELASTICSEARCH_URL : <http://elasticsearch:9200> # URL de Elasticsearch En cuanto al servicio de Filebeat: Este servicio es un emisor que centraliza los logs de diferentes ubicaciones. Es importante resaltar que se configura con permisos de solo lectura (:ro) para mayor seguridad. Al no requerir escritura, se reduce un punto de vulnerabilidad en el sistema - ./filebeat.yml:/usr/share/filebeat/filebeat.yml:ro El servicio de Logstash: se encarga de procesar y enriquecer los datos de los eventos antes de enviarlos a Elasticsearch. Realiza tareas como la conversi\u00f3n y eliminaci\u00f3n de datos cr\u00edticos o sensibles. Logstash utiliza su puerto por defecto y tambi\u00e9n depende de Elasticsearch para enviar los datos procesados.. Por otro lado, el servicio de Suricata es una herramienta de detecci\u00f3n de amenazas y prevenci\u00f3n de intrusiones en red. Su configuraci\u00f3n es ligeramente diferente, ya que vigila constantemente la red y requiere algunas configuraciones adicionales. Tambi\u00e9n se configura como de solo lectura (:ro) debido a que es un sistema de eventos en tiempo real. Vigila las amenazas y detecta cualquier actividad maliciosa para minimizar el da\u00f1o posible. Se especifica la interfaz a la que Suricata estar\u00e1 atento y se pueden configurar diferentes opciones seg\u00fan las necesidades. Finalmente, el archivo de Docker Compose tambi\u00e9n incluye la versi\u00f3n del mismo y los vol\u00famenes necesarios para almacenar los datos de Elasticsearch - ./suricata.yaml:/etc/suricata/suricata.yaml:ro # Archivo de configuraci\u00f3n de Suricata network_mode : \"host\" command : -c /etc/suricata/suricata.yaml -i eth0 # Comando para ejecutar Suricata Tambi\u00e9n hay que especificar la interfaz que vigila y se puede especificar con distitnas opciones. version : '3.7' # Versi\u00f3n de la sintaxis del archivo docker-compose services : elasticsearch : # Servicio de Elasticsearch image : docker.elastic.co/elasticsearch/elasticsearch:7.15.2 # Imagen utilizada para el contenedor container_name : elasticsearch # Nombre del contenedor environment : - node.name=elasticsearch # Configuraci\u00f3n del nombre del nodo Elasticsearch - cluster.name=es-docker-cluster # Configuraci\u00f3n del nombre del cl\u00faster Elasticsearch - bootstrap.memory_lock=true # Configuraci\u00f3n para bloquear la memoria - \"ES_JAVA_OPTS=-Xms512m -Xmx512m\" # Opciones de configuraci\u00f3n para la memoria de Elasticsearch - \"discovery.type=single-node\" # Configuraci\u00f3n del tipo de descubrimiento del nodo Elasticsearch - \"xpack.security.enabled=false\" # Configuraci\u00f3n para deshabilitar la seguridad de X-Pack ulimits : memlock : soft : -1 # L\u00edmite blando para bloqueo de memoria hard : -1 # L\u00edmite duro para bloqueo de memoria volumes : - esdata:/usr/share/elasticsearch/data # Volumen utilizado para almacenar los datos de Elasticsearch ports : - 9200:9200 # Mapeo del puerto del contenedor al puerto del host kibana : # Servicio de Kibana image : docker.elastic.co/kibana/kibana:7.15.2 # Imagen utilizada para el contenedor container_name : kibana # Nombre del contenedor ports : - 5601:5601 # Mapeo del puerto del contenedor al puerto del host environment : ELASTICSEARCH_URL : http://elasticsearch:9200/ # URL de Elasticsearch volumes : - ./kibana.yml:/usr/share/kibana/config/kibana.yml # Volumen utilizado para la configuraci\u00f3n de Kibana depends_on : - elasticsearch # Dependencia del servicio de Elasticsearch filebeat : # Servicio de Filebeat image : docker.elastic.co/beats/filebeat:7.15.2 # Imagen utilizada para el contenedor container_name : filebeat # Nombre del contenedor user : root volumes : - ./filebeat.yml:/usr/share/filebeat/filebeat.yml:ro # Volumen utilizado para la configuraci\u00f3n de Filebeat - /var/log:/var/log:ro # Mapeo del directorio de logs del host al contenedor depends_on : - elasticsearch # Dependencia del servicio de Elasticsearch logstash : # Servicio de Logstash image : docker.elastic.co/logstash/logstash:7.15.2 # Imagen utilizada para el contenedor container_name : logstash # Nombre del contenedor volumes : - ./logstash.conf:/usr/share/logstash/pipeline/logstash.conf:ro # Volumen utilizado para la configuraci\u00f3n de Logstash ports : - 5044:5044 # Mapeo del puerto del contenedor al puerto del host depends_on : - elasticsearch # Dependencia del servicio de Elasticsearch suricata : # Servicio de Suricata image : jasonish/suricata:latest # Imagen utilizada para el contenedor user : root privileged : true volumes : - /var/log/suricata:/var/log/suricata # Mapeo del directorio de logs del host al contenedor - ./suricata.yaml:/etc/suricata/suricata.yaml:ro # Volumen utilizado para la configuraci\u00f3n de Suricata - /var/lib/suricata/rules:/var/lib/suricata/rules # Mapeo del directorio de reglas del host al contenedor - /etc/suricata/classification.config:/etc/suricata/classification.config # Mapeo del archivo de clasificaci\u00f3n del host al contenedor network_mode : \"host\" # Modo de red utilizado (comparte la red del host) command : -c /etc/suricata/suricata.yaml -i enp0s3 # Comando a ejecutar dentro del contenedor de Suricata volumes : esdata : driver : local # Tipo de driver de volumen utilizado (local) networks : default : external : name : encriptadisimo # Nombre de la red externa utilizada","title":"Docker-Compose.yml"},{"location":"Documentaci%C3%B3n/Archivos-de-configuraci%C3%B3n/filebeat/","text":"Filebeat.yml \u00b6 El archivo que estamos revisando es bastante sencillo y cumple la funci\u00f3n de centralizar los logs. Podemos observar que recibe los registros de todos los sistemas a trav\u00e9s de los paths indicados. Es importante destacar que no hay l\u00edmites establecidos, lo que significa que el sistema puede escalar f\u00e1cilmente para manejar grandes vol\u00famenes de logs. Adem\u00e1s, hay una verificaci\u00f3n espec\u00edfica que se realiza en el archivo auth.log, lo que proporciona un sistema seguro de autenticaci\u00f3n. Si examinamos el c\u00f3digo a continuaci\u00f3n, podemos ver que la salida de los logs se env\u00eda a Logstash, ya que este es el siguiente paso en el procesamiento de un evento filebeat.inputs : # Configuraci\u00f3n de los inputs de Filebeat - type : log # Tipo de input (logs) enabled : true # Habilitar este input paths : # Rutas de los archivos de log a monitorear - /var/log/*.log # Todos los archivos de log en el directorio /var/log - /var/log/syslog # Archivo de log del sistema syslog - /var/log/nginx/*.log # Todos los archivos de log de Nginx en el directorio /var/log/nginx - /var/log/apache2/*.log # Todos los archivos de log de Apache en el directorio /var/log/apache2 - /var/log/mysql/error.log # Archivo de log de errores de MySQL - /var/log/postgresql/*.log # Todos los archivos de log de PostgreSQL en el directorio /var/log/postgresql - /var/log/suricata/eve.json # Archivo de log de eventos de Suricata en formato JSON - /var/log/packetbeat/* # Todos los archivos de log de Packetbeat filebeat.modules : # Configuraci\u00f3n de los m\u00f3dulos de Filebeat - module : system # M\u00f3dulo de sistema syslog : enabled : false # Deshabilitar el procesamiento de logs del sistema syslog auth : enabled : true # Habilitar el procesamiento de logs de autenticaci\u00f3n var.paths : [ \"/var/log/auth.log\" ] # Ruta del archivo de log de autenticaci\u00f3n output.logstash : # Configuraci\u00f3n de la salida hacia Logstash hosts : [ \"logstash:5044\" ] # Host y puerto de Logstash setup.kibana : # Configuraci\u00f3n de la conexi\u00f3n con Kibana host : \"kibana:5601\" # Host y puerto de Kibana fields : # Campos personalizados para los eventos de Filebeat event.dataset : keyword # Campo para el dataset de evento","title":"Filebeat.yml"},{"location":"Documentaci%C3%B3n/Archivos-de-configuraci%C3%B3n/filebeat/#filebeatyml","text":"El archivo que estamos revisando es bastante sencillo y cumple la funci\u00f3n de centralizar los logs. Podemos observar que recibe los registros de todos los sistemas a trav\u00e9s de los paths indicados. Es importante destacar que no hay l\u00edmites establecidos, lo que significa que el sistema puede escalar f\u00e1cilmente para manejar grandes vol\u00famenes de logs. Adem\u00e1s, hay una verificaci\u00f3n espec\u00edfica que se realiza en el archivo auth.log, lo que proporciona un sistema seguro de autenticaci\u00f3n. Si examinamos el c\u00f3digo a continuaci\u00f3n, podemos ver que la salida de los logs se env\u00eda a Logstash, ya que este es el siguiente paso en el procesamiento de un evento filebeat.inputs : # Configuraci\u00f3n de los inputs de Filebeat - type : log # Tipo de input (logs) enabled : true # Habilitar este input paths : # Rutas de los archivos de log a monitorear - /var/log/*.log # Todos los archivos de log en el directorio /var/log - /var/log/syslog # Archivo de log del sistema syslog - /var/log/nginx/*.log # Todos los archivos de log de Nginx en el directorio /var/log/nginx - /var/log/apache2/*.log # Todos los archivos de log de Apache en el directorio /var/log/apache2 - /var/log/mysql/error.log # Archivo de log de errores de MySQL - /var/log/postgresql/*.log # Todos los archivos de log de PostgreSQL en el directorio /var/log/postgresql - /var/log/suricata/eve.json # Archivo de log de eventos de Suricata en formato JSON - /var/log/packetbeat/* # Todos los archivos de log de Packetbeat filebeat.modules : # Configuraci\u00f3n de los m\u00f3dulos de Filebeat - module : system # M\u00f3dulo de sistema syslog : enabled : false # Deshabilitar el procesamiento de logs del sistema syslog auth : enabled : true # Habilitar el procesamiento de logs de autenticaci\u00f3n var.paths : [ \"/var/log/auth.log\" ] # Ruta del archivo de log de autenticaci\u00f3n output.logstash : # Configuraci\u00f3n de la salida hacia Logstash hosts : [ \"logstash:5044\" ] # Host y puerto de Logstash setup.kibana : # Configuraci\u00f3n de la conexi\u00f3n con Kibana host : \"kibana:5601\" # Host y puerto de Kibana fields : # Campos personalizados para los eventos de Filebeat event.dataset : keyword # Campo para el dataset de evento","title":"Filebeat.yml"},{"location":"Documentaci%C3%B3n/Archivos-de-configuraci%C3%B3n/logstash/","text":"Logstash.yml \u00b6 Aqu\u00ed tienes el texto mejorado y con una explicaci\u00f3n m\u00e1s clara: En el archivo logstash.yml, podemos observar los filtros que se aplican a cada evento que pasa por Logstash. Normalmente, Logstash se configura con filtros espec\u00edficos que se centran en recopilar datos vitales y de suma importancia para los encargados de monitorear el sistema. En este caso particular, se filtran los eventos del sistema relacionados con \"system\" y \"auth\", es decir, eventos relacionados con la autenticaci\u00f3n y los procesos internos del sistema. Podemos ver que se aplican dos condiciones \"if\" aplicadas a \"system\" y \"auth\" que serian las reglas para recopilar los eventos deseados. Al final del archivo, encontramos el uso de la funci\u00f3n \"grok\", que se utiliza para analizar y extraer datos de los eventos del sistema. En este caso, se est\u00e1n filtrando conexiones SSH y acciones de \"sudo\". Tambi\u00e9n se incluye un registro de la hora en que se guarda el evento. Finalmente, se indica que el evento debe seguir su camino y llegar a Elasticsearch, donde se especifica el host y el puerto donde se encuentra Elasticsearch. input { beats { # Configuraci\u00f3n de la entrada de datos desde Beats port => 5044 # Puerto en el que Beats enviar\u00e1 los datos } } filter { if [fileset][module] == \"system\" { # Filtrar los eventos del m\u00f3dulo \"system\" en el archivo de configuraci\u00f3n de Filebeat if [fileset][name] == \"auth\" { # Filtrar los eventos del fileset \"auth\" en el archivo de configuraci\u00f3n de Filebeat grok { # Utilizar el filtro grok para extraer campos estructurados de los mensajes de log match => { # Patrones de coincidencia para extraer los campos \"message\" => [ # Campo \"message\" a analizar \"%{SYSLOGTIMESTAMP:[system][auth][timestamp]} %{SYSLOGHOST:[system][auth][hostname]} sshd(?: \\ [%{POSINT:[system][auth][pid]} \\ ])?: %{DATA:[system][auth][ssh][event]} %{DATA:[system][auth][ssh][method]} %{DATA:[system][auth][ssh][username]} %{DATA:[system][auth][ssh][ip]}(?: %{GREEDYDATA:[system][auth][ssh][data]})?\" , \"%{SYSLOGTIMESTAMP:[system][auth][timestamp]} %{SYSLOGHOST:[system][auth][hostname]} sudo(?: \\ [%{POSINT:[system][auth][pid]} \\ ])?: %{DATA:[system][auth][user]} %{DATA:[system][auth][sudo][tty]}=%{DATA:[system][auth][sudo][user]}(?: \\ (%{DATA:[system][auth][sudo][runas]} \\ ))?: %{GREEDYDATA:[system][auth][sudo][command]}\" ] } pattern_definitions => { # Definiciones de patrones personalizados \"GREEDYDATA\" => \".*\" # Patr\u00f3n que coincide con cualquier cadena de caracteres } remove_field => \"message\" # Eliminar el campo \"message\" original despu\u00e9s de extraer los campos estructurados } mutate { # Realizar mutaciones en los eventos rename => { \"@timestamp\" => \"read_timestamp\" } # Renombrar el campo \"@timestamp\" a \"read_timestamp\" } date { # Convertir el campo de fecha y hora a un formato reconocido match => [ \"[system][auth][timestamp]\", \"MMM d HH:mm:ss\", \"MMM dd HH:mm:ss\" ] # Patrones de coincidencia de fecha y hora } geoip { # Realizar una consulta de GeoIP para enriquecer el evento con informaci\u00f3n de geolocalizaci\u00f3n source => \"[system][auth][ssh][ip]\" # Campo que contiene la direcci\u00f3n IP target => \"[system][auth][ssh][geoip]\" # Campo que contendr\u00e1 la informaci\u00f3n de geolocalizaci\u00f3n } if [system][auth][sudo][command] { # Verificar si el campo \"system.auth.sudo.command\" existe grok { # Utilizar el filtro grok para extraer campos estructurados del comando sudo match => { \"[system][auth][sudo][command]\" => \"^ %{USER:[system][auth][sudo][run_as_user]} : TTY=%{DATA:[system][auth][sudo][tty]} ; PWD=%{DATA:[system][auth][sudo][pwd]} ; USER=%{USER:[system][auth][sudo][user]} ; COMMAND=%{GREEDYDATA:[system][auth][sudo][command]}\" } } } } } } output { elasticsearch { # Configuraci\u00f3n de la salida hacia Elasticsearch hosts => [\"elasticsearch:9200\"] # Host y puerto de Elasticsearch manage_template => false # Deshabilitar la gesti\u00f3n de plantillas en Elasticsearch index => \"filebeat\" # Nombre del \u00edndice en Elasticsearch } }","title":"Logstash.yml"},{"location":"Documentaci%C3%B3n/Archivos-de-configuraci%C3%B3n/logstash/#logstashyml","text":"Aqu\u00ed tienes el texto mejorado y con una explicaci\u00f3n m\u00e1s clara: En el archivo logstash.yml, podemos observar los filtros que se aplican a cada evento que pasa por Logstash. Normalmente, Logstash se configura con filtros espec\u00edficos que se centran en recopilar datos vitales y de suma importancia para los encargados de monitorear el sistema. En este caso particular, se filtran los eventos del sistema relacionados con \"system\" y \"auth\", es decir, eventos relacionados con la autenticaci\u00f3n y los procesos internos del sistema. Podemos ver que se aplican dos condiciones \"if\" aplicadas a \"system\" y \"auth\" que serian las reglas para recopilar los eventos deseados. Al final del archivo, encontramos el uso de la funci\u00f3n \"grok\", que se utiliza para analizar y extraer datos de los eventos del sistema. En este caso, se est\u00e1n filtrando conexiones SSH y acciones de \"sudo\". Tambi\u00e9n se incluye un registro de la hora en que se guarda el evento. Finalmente, se indica que el evento debe seguir su camino y llegar a Elasticsearch, donde se especifica el host y el puerto donde se encuentra Elasticsearch. input { beats { # Configuraci\u00f3n de la entrada de datos desde Beats port => 5044 # Puerto en el que Beats enviar\u00e1 los datos } } filter { if [fileset][module] == \"system\" { # Filtrar los eventos del m\u00f3dulo \"system\" en el archivo de configuraci\u00f3n de Filebeat if [fileset][name] == \"auth\" { # Filtrar los eventos del fileset \"auth\" en el archivo de configuraci\u00f3n de Filebeat grok { # Utilizar el filtro grok para extraer campos estructurados de los mensajes de log match => { # Patrones de coincidencia para extraer los campos \"message\" => [ # Campo \"message\" a analizar \"%{SYSLOGTIMESTAMP:[system][auth][timestamp]} %{SYSLOGHOST:[system][auth][hostname]} sshd(?: \\ [%{POSINT:[system][auth][pid]} \\ ])?: %{DATA:[system][auth][ssh][event]} %{DATA:[system][auth][ssh][method]} %{DATA:[system][auth][ssh][username]} %{DATA:[system][auth][ssh][ip]}(?: %{GREEDYDATA:[system][auth][ssh][data]})?\" , \"%{SYSLOGTIMESTAMP:[system][auth][timestamp]} %{SYSLOGHOST:[system][auth][hostname]} sudo(?: \\ [%{POSINT:[system][auth][pid]} \\ ])?: %{DATA:[system][auth][user]} %{DATA:[system][auth][sudo][tty]}=%{DATA:[system][auth][sudo][user]}(?: \\ (%{DATA:[system][auth][sudo][runas]} \\ ))?: %{GREEDYDATA:[system][auth][sudo][command]}\" ] } pattern_definitions => { # Definiciones de patrones personalizados \"GREEDYDATA\" => \".*\" # Patr\u00f3n que coincide con cualquier cadena de caracteres } remove_field => \"message\" # Eliminar el campo \"message\" original despu\u00e9s de extraer los campos estructurados } mutate { # Realizar mutaciones en los eventos rename => { \"@timestamp\" => \"read_timestamp\" } # Renombrar el campo \"@timestamp\" a \"read_timestamp\" } date { # Convertir el campo de fecha y hora a un formato reconocido match => [ \"[system][auth][timestamp]\", \"MMM d HH:mm:ss\", \"MMM dd HH:mm:ss\" ] # Patrones de coincidencia de fecha y hora } geoip { # Realizar una consulta de GeoIP para enriquecer el evento con informaci\u00f3n de geolocalizaci\u00f3n source => \"[system][auth][ssh][ip]\" # Campo que contiene la direcci\u00f3n IP target => \"[system][auth][ssh][geoip]\" # Campo que contendr\u00e1 la informaci\u00f3n de geolocalizaci\u00f3n } if [system][auth][sudo][command] { # Verificar si el campo \"system.auth.sudo.command\" existe grok { # Utilizar el filtro grok para extraer campos estructurados del comando sudo match => { \"[system][auth][sudo][command]\" => \"^ %{USER:[system][auth][sudo][run_as_user]} : TTY=%{DATA:[system][auth][sudo][tty]} ; PWD=%{DATA:[system][auth][sudo][pwd]} ; USER=%{USER:[system][auth][sudo][user]} ; COMMAND=%{GREEDYDATA:[system][auth][sudo][command]}\" } } } } } } output { elasticsearch { # Configuraci\u00f3n de la salida hacia Elasticsearch hosts => [\"elasticsearch:9200\"] # Host y puerto de Elasticsearch manage_template => false # Deshabilitar la gesti\u00f3n de plantillas en Elasticsearch index => \"filebeat\" # Nombre del \u00edndice en Elasticsearch } }","title":"Logstash.yml"},{"location":"Documentaci%C3%B3n/Archivos-de-configuraci%C3%B3n/suricata/","text":"Suricata.yml \u00b6 Suricata es una herramienta de vigilancia de red que se enfoca en el tr\u00e1fico de red y en el env\u00edo de alertas. Las configuraciones aplicadas a Suricata son un poco diferentes, ya que su objetivo principal es analizar y detectar eventos en la red, sin necesidad de recopilar datos. En las configuraciones de Suricata se pueden observar reglas relacionadas con el tr\u00e1fico de Internet, validaci\u00f3n de usuarios, registro de la actividad y especificaciones detalladas para la captura de paquetes, interfaces de red utilizadas para la captura, registro de eventos HTTP y un cuidado especial en la gesti\u00f3n de claves de cifrado. Al final del archivo, se especifica qu\u00e9 registros est\u00e1 observando Suricata, es decir, qu\u00e9 eventos o actividades est\u00e1 monitoreando en la red. types : - alert # Tipos de eventos EVE a registrar (alertas) - http # Tipos de eventos EVE a registrar (HTTP) - dns # Tipos de eventos EVE a registrar (DNS) - tls # Tipos de eventos EVE a registrar (TLS) %YAML 1.1 --- # Configuraci\u00f3n de Suricata default-log-dir : /var/log/suricata/ # Definici\u00f3n de las reglas rule-files : - /var/lib/suricata/rules/*.rules # Configuraci\u00f3n de los registros outputs : - fast : # Configuraci\u00f3n de la salida r\u00e1pida enabled : yes # Habilitar la salida r\u00e1pida filename : fast.log # Nombre del archivo de salida r\u00e1pida append : yes # Agregar al archivo de salida r\u00e1pida existente si existe - eve-log : # Configuraci\u00f3n de la salida de registros EVE enabled : yes # Habilitar la salida de registros EVE filetype : regular # Tipo de archivo de salida de registros EVE filename : eve.json # Nombre del archivo de salida de registros EVE append : yes # Agregar al archivo de salida de registros EVE existente si existe - syslog : # Configuraci\u00f3n de la salida de registros syslog enabled : yes # Habilitar la salida de registros syslog # Configuraci\u00f3n de la detecci\u00f3n de anomal\u00edas anomaly : detection-ports : - 21 # Puerto FTP - 22 # Puerto SSH - 23 # Puerto Telnet - 25 # Puerto SMTP - 80 # Puerto HTTP # Configuraci\u00f3n de los protocolos de capa de aplicaci\u00f3n app-layer : protocols : dcerpc : enabled : yes smb : enabled : yes ftp : enabled : yes ssh : enabled : yes smtp : enabled : yes dns : enabled : yes modbus : enabled : no http : enabled : yes tls : enabled : yes enip : enabled : yes dnp3 : enabled : yes nfs : enabled : yes ntp : enabled : yes tftp : enabled : yes ikev2 : enabled : yes krb5 : enabled : yes dhcp : enabled : yes snmp : enabled : yes sip : enabled : yes rfb : enabled : yes mqtt : enabled : yes rdp : enabled : yes http2 : enabled : yes imap : enabled : yes # Configuraci\u00f3n de las interfaces af-packet : - interface : enp0s3 # Nombre de la interfaz de red a utilizar cluster-id : 99 # ID del cl\u00faster cluster-type : cluster_flow # Tipo de cl\u00faster defrag : yes # Habilitar la desfragmentaci\u00f3n de paquetes # Configuraci\u00f3n de la preprocesamiento prelude : enabled : yes # Habilitar la integraci\u00f3n con Prelude log-dir : /var/log/suricata/ # Directorio de registro de Prelude # Configuraci\u00f3n de la extracci\u00f3n de archivos file-extraction : enabled : yes # Habilitar la extracci\u00f3n de archivos directory : /var/log/suricata/files # Directorio donde se almacenan los archivos extra\u00eddos # Configuraci\u00f3n de los registros HTTP http-log : enabled : yes # Habilitar el registro de eventos HTTP filetype : regular # Tipo de archivo de salida de registros HTTP filename : http.log # Nombre del archivo de salida de registros HTTP append : yes # Agregar al archivo de salida de registros HTTP existente si existe extended : yes # Habilitar registros HTTP extendidos # Configuraci\u00f3n de los registros TLS tls-log : enabled : yes # Habilitar el registro de eventos TLS filetype : regular # Tipo de archivo de salida de registros TLS filename : tls.log # Nombre del archivo de salida de registros TLS append : yes # Agregar al archivo de salida de registros TLS existente si existe extended : yes # Habilitar registros TLS extendidos","title":"Suricata.yml"},{"location":"Documentaci%C3%B3n/Archivos-de-configuraci%C3%B3n/suricata/#suricatayml","text":"Suricata es una herramienta de vigilancia de red que se enfoca en el tr\u00e1fico de red y en el env\u00edo de alertas. Las configuraciones aplicadas a Suricata son un poco diferentes, ya que su objetivo principal es analizar y detectar eventos en la red, sin necesidad de recopilar datos. En las configuraciones de Suricata se pueden observar reglas relacionadas con el tr\u00e1fico de Internet, validaci\u00f3n de usuarios, registro de la actividad y especificaciones detalladas para la captura de paquetes, interfaces de red utilizadas para la captura, registro de eventos HTTP y un cuidado especial en la gesti\u00f3n de claves de cifrado. Al final del archivo, se especifica qu\u00e9 registros est\u00e1 observando Suricata, es decir, qu\u00e9 eventos o actividades est\u00e1 monitoreando en la red. types : - alert # Tipos de eventos EVE a registrar (alertas) - http # Tipos de eventos EVE a registrar (HTTP) - dns # Tipos de eventos EVE a registrar (DNS) - tls # Tipos de eventos EVE a registrar (TLS) %YAML 1.1 --- # Configuraci\u00f3n de Suricata default-log-dir : /var/log/suricata/ # Definici\u00f3n de las reglas rule-files : - /var/lib/suricata/rules/*.rules # Configuraci\u00f3n de los registros outputs : - fast : # Configuraci\u00f3n de la salida r\u00e1pida enabled : yes # Habilitar la salida r\u00e1pida filename : fast.log # Nombre del archivo de salida r\u00e1pida append : yes # Agregar al archivo de salida r\u00e1pida existente si existe - eve-log : # Configuraci\u00f3n de la salida de registros EVE enabled : yes # Habilitar la salida de registros EVE filetype : regular # Tipo de archivo de salida de registros EVE filename : eve.json # Nombre del archivo de salida de registros EVE append : yes # Agregar al archivo de salida de registros EVE existente si existe - syslog : # Configuraci\u00f3n de la salida de registros syslog enabled : yes # Habilitar la salida de registros syslog # Configuraci\u00f3n de la detecci\u00f3n de anomal\u00edas anomaly : detection-ports : - 21 # Puerto FTP - 22 # Puerto SSH - 23 # Puerto Telnet - 25 # Puerto SMTP - 80 # Puerto HTTP # Configuraci\u00f3n de los protocolos de capa de aplicaci\u00f3n app-layer : protocols : dcerpc : enabled : yes smb : enabled : yes ftp : enabled : yes ssh : enabled : yes smtp : enabled : yes dns : enabled : yes modbus : enabled : no http : enabled : yes tls : enabled : yes enip : enabled : yes dnp3 : enabled : yes nfs : enabled : yes ntp : enabled : yes tftp : enabled : yes ikev2 : enabled : yes krb5 : enabled : yes dhcp : enabled : yes snmp : enabled : yes sip : enabled : yes rfb : enabled : yes mqtt : enabled : yes rdp : enabled : yes http2 : enabled : yes imap : enabled : yes # Configuraci\u00f3n de las interfaces af-packet : - interface : enp0s3 # Nombre de la interfaz de red a utilizar cluster-id : 99 # ID del cl\u00faster cluster-type : cluster_flow # Tipo de cl\u00faster defrag : yes # Habilitar la desfragmentaci\u00f3n de paquetes # Configuraci\u00f3n de la preprocesamiento prelude : enabled : yes # Habilitar la integraci\u00f3n con Prelude log-dir : /var/log/suricata/ # Directorio de registro de Prelude # Configuraci\u00f3n de la extracci\u00f3n de archivos file-extraction : enabled : yes # Habilitar la extracci\u00f3n de archivos directory : /var/log/suricata/files # Directorio donde se almacenan los archivos extra\u00eddos # Configuraci\u00f3n de los registros HTTP http-log : enabled : yes # Habilitar el registro de eventos HTTP filetype : regular # Tipo de archivo de salida de registros HTTP filename : http.log # Nombre del archivo de salida de registros HTTP append : yes # Agregar al archivo de salida de registros HTTP existente si existe extended : yes # Habilitar registros HTTP extendidos # Configuraci\u00f3n de los registros TLS tls-log : enabled : yes # Habilitar el registro de eventos TLS filetype : regular # Tipo de archivo de salida de registros TLS filename : tls.log # Nombre del archivo de salida de registros TLS append : yes # Agregar al archivo de salida de registros TLS existente si existe extended : yes # Habilitar registros TLS extendidos","title":"Suricata.yml"},{"location":"Documentaci%C3%B3n/Docker/RedEncriptadaconDocker/","text":"Red Encriptada con Docker \u00b6 Docker tiene la capacidad de crear redes de superposici\u00f3n con cifrado habilitado para proteger el tr\u00e1fico entre contenedores en diferentes hosts de Docker. Esto se logra mediante el uso de IPSec, un conjunto de protocolos y algoritmos para encriptar y autenticar paquetes IP. Cuando se habilita el cifrado en una red de superposici\u00f3n, Docker configura autom\u00e1ticamente IPSec para encriptar el tr\u00e1fico utilizando el algoritmo AES de 256 bits. Esto significa que los paquetes enviados desde un contenedor a otro en la misma red de superposici\u00f3n se encriptan antes de salir del host de origen y se desencriptan al llegar al host de destino, sin requerir ninguna configuraci\u00f3n adicional. Sin embargo, es importante tener en cuenta que este cifrado puede tener un impacto en el rendimiento de la red y en la carga del CPU. Por lo tanto, es necesario evaluar si el cifrado es necesario en funci\u00f3n de los requisitos de seguridad. Primero activar\u00edamos el comando docker swarm init , que es un gestor de contenedores, pero en este caso solo utilizaremos las funciones de red. # Red Encriptada de Docker sudo docker swarm init #Comando generar red, es importante la opcion '--attachable' para poderlo ejecutar ya que sin esta opci\u00f3n nos haria falta el sistema montado sobre docker swarm sudo docker network create --opt encrypted --attachable --driver overlay encriptadisimo Una vez creada la red, nos dirigimos a nuestro archivo docker-compose o script correspondiente y al final del mismo generamos la red encriptada de Docker, indicando el nombre especificado en el comando. networks : default : external : name : encriptadisimo","title":"Red Encriptada con Docker"},{"location":"Documentaci%C3%B3n/Docker/RedEncriptadaconDocker/#red-encriptada-con-docker","text":"Docker tiene la capacidad de crear redes de superposici\u00f3n con cifrado habilitado para proteger el tr\u00e1fico entre contenedores en diferentes hosts de Docker. Esto se logra mediante el uso de IPSec, un conjunto de protocolos y algoritmos para encriptar y autenticar paquetes IP. Cuando se habilita el cifrado en una red de superposici\u00f3n, Docker configura autom\u00e1ticamente IPSec para encriptar el tr\u00e1fico utilizando el algoritmo AES de 256 bits. Esto significa que los paquetes enviados desde un contenedor a otro en la misma red de superposici\u00f3n se encriptan antes de salir del host de origen y se desencriptan al llegar al host de destino, sin requerir ninguna configuraci\u00f3n adicional. Sin embargo, es importante tener en cuenta que este cifrado puede tener un impacto en el rendimiento de la red y en la carga del CPU. Por lo tanto, es necesario evaluar si el cifrado es necesario en funci\u00f3n de los requisitos de seguridad. Primero activar\u00edamos el comando docker swarm init , que es un gestor de contenedores, pero en este caso solo utilizaremos las funciones de red. # Red Encriptada de Docker sudo docker swarm init #Comando generar red, es importante la opcion '--attachable' para poderlo ejecutar ya que sin esta opci\u00f3n nos haria falta el sistema montado sobre docker swarm sudo docker network create --opt encrypted --attachable --driver overlay encriptadisimo Una vez creada la red, nos dirigimos a nuestro archivo docker-compose o script correspondiente y al final del mismo generamos la red encriptada de Docker, indicando el nombre especificado en el comando. networks : default : external : name : encriptadisimo","title":"Red Encriptada con Docker"},{"location":"Documentaci%C3%B3n/Docker/docker-compose/","text":"Instalaci\u00f3n Docker Compose \u00b6 Una vez terminada la instalaci\u00f3n de Docker, pasamos a instalar Docker Compose para automatizar el montaje utilizando los archivos YAML indicados en el apartado de configuraciones. Docker Compose consta de un archivo central llamado \"docker-compose.yml\" que monta todos los contenedores con las configuraciones espec\u00edficas requeridas para cada servicio. Esto se debe a que el consumo de recursos no es el mismo en todos los servicios, y se recogen las configuraciones espec\u00edficas de cada servicio en sus respectivos archivos YAML. # Descarga el archivo ejecutable de Docker Compose desde el repositorio oficial de GitHub sudo curl -L \"https://github.com/docker/compose/releases/download/1.29.2/docker-compose- $( uname -s ) - $( uname -m ) \" -o /usr/local/bin/docker-compose # Otorga permisos de ejecuci\u00f3n al archivo de Docker Compose sudo chmod +x /usr/local/bin/docker-compose","title":"Instalaci\u00f3n Docker Compose"},{"location":"Documentaci%C3%B3n/Docker/docker-compose/#instalacion-docker-compose","text":"Una vez terminada la instalaci\u00f3n de Docker, pasamos a instalar Docker Compose para automatizar el montaje utilizando los archivos YAML indicados en el apartado de configuraciones. Docker Compose consta de un archivo central llamado \"docker-compose.yml\" que monta todos los contenedores con las configuraciones espec\u00edficas requeridas para cada servicio. Esto se debe a que el consumo de recursos no es el mismo en todos los servicios, y se recogen las configuraciones espec\u00edficas de cada servicio en sus respectivos archivos YAML. # Descarga el archivo ejecutable de Docker Compose desde el repositorio oficial de GitHub sudo curl -L \"https://github.com/docker/compose/releases/download/1.29.2/docker-compose- $( uname -s ) - $( uname -m ) \" -o /usr/local/bin/docker-compose # Otorga permisos de ejecuci\u00f3n al archivo de Docker Compose sudo chmod +x /usr/local/bin/docker-compose","title":"Instalaci\u00f3n Docker Compose"},{"location":"Documentaci%C3%B3n/Docker/docker/","text":"Instalaci\u00f3n Docker \u00b6 Para empezar, necesitaremos instalar Docker en nuestro sistema siguiendo los pasos que veremos a continuaci\u00f3n sudo apt-get update #Actualizamos el sistema Instala los paquetes necesarios para permitir el uso de repositorios seguros y descargas a trav\u00e9s de HTTPS. sudo apt-get install apt-transport-https ca-certificates curl gnupg lsb-release Descarga la clave de GPG de Docker y gu\u00e1rdala en el archivo \"docker-archive-keyring.gpg\" en la carpeta \"/usr/share/keyrings/\". curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg Agrega la entrada del repositorio de Docker al archivo \"/etc/apt/sources.list.d/docker.list Utiliza el valor de \"lsb_release -cs\" para obtener el nombre del c\u00f3digo de la versi\u00f3n de Ubuntu actual echo \"deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu $( lsb_release -cs ) stable\" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null Actualiza la lista de paquetes disponibles en los repositorios configurados en el sistema sudo apt-get update Instala Docker Community Edition (CE), Docker CLI y Containerd.io sudo apt-get install docker-ce docker-ce-cli containerd.io","title":"Instalaci\u00f3n Docker"},{"location":"Documentaci%C3%B3n/Docker/docker/#instalacion-docker","text":"Para empezar, necesitaremos instalar Docker en nuestro sistema siguiendo los pasos que veremos a continuaci\u00f3n sudo apt-get update #Actualizamos el sistema Instala los paquetes necesarios para permitir el uso de repositorios seguros y descargas a trav\u00e9s de HTTPS. sudo apt-get install apt-transport-https ca-certificates curl gnupg lsb-release Descarga la clave de GPG de Docker y gu\u00e1rdala en el archivo \"docker-archive-keyring.gpg\" en la carpeta \"/usr/share/keyrings/\". curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg Agrega la entrada del repositorio de Docker al archivo \"/etc/apt/sources.list.d/docker.list Utiliza el valor de \"lsb_release -cs\" para obtener el nombre del c\u00f3digo de la versi\u00f3n de Ubuntu actual echo \"deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu $( lsb_release -cs ) stable\" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null Actualiza la lista de paquetes disponibles en los repositorios configurados en el sistema sudo apt-get update Instala Docker Community Edition (CE), Docker CLI y Containerd.io sudo apt-get install docker-ce docker-ce-cli containerd.io","title":"Instalaci\u00f3n Docker"},{"location":"Instalaci%C3%B3n/git/","text":"GITHUB \u00b6 Documentaci\u00f3n del proyecto \u00b6 Link git proyecto: https://github.com/rodrigochavezlava/ProyectoSIEM Clonar git del script: $ git clone https://github.com/rodrigochavezlava/ProyectoSIEM/blob/main/SIEMProyecto.sh Script del proyecto \u00b6 Recordemos que la idea de este script es ejecutarlo en nuestra m\u00e1quina para tener un SIEM completamente funcional con tan solo un comando. Todo esto se consigue mediante la uni\u00f3n de diferentes servicios a trav\u00e9s de contenedores. #!/bin/bash # Solicitar al usuario que ingrese un valor echo \"Ingresa el nombre de la tarjeta de red que desees analizar:\" read tarjetaRed echo \"Escoge la contrase\u00f1a de tu encriptaci\u00f3n de red | min: 32 caracteres\" read claveEncriptacionRed #Calcula el numero de caracteres de la contrase\u00f1a con el # longitud = ${# claveEncriptacionRed } echo \"La longitud de la contrase\u00f1a es: $longitud caracteres.\" #Compara longitud en caso de ser menor de 32 se para if [ $longitud -ge 32 ] ; then echo \"La contrase\u00f1a tiene 32 caracteres.\" else echo \"La contrase\u00f1a no tiene 32 caracteres, SALIENDO.\" exit fi #Inicio sudo apt-get update -y #Paquetes para uso de repositorios seguros HTTPS sudo apt-get install -y apt-transport-https ca-certificates curl gnupg lsb-release #Claves GPG y volcarlas en /usr/share/keyrings curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg #A\u00f1adir la direccion de los repositorios al sistema echo \"deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu $( lsb_release -cs ) stable\" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null #Actualizar el repositorio sudo apt-get update -y #Instalar Docker sudo apt-get install -y docker-ce docker-ce-cli containerd.io #Descargar Docker Compose sudo curl -L \"https://github.com/docker/compose/releases/download/1.29.2/docker-compose- $( uname -s ) - $( uname -m ) \" -o /usr/local/bin/docker-compose #Dar permisos para ejecutar al Docker Compose sudo chmod +x /usr/local/bin/docker-compose #Creacion docker compose - Redirije el contenido del EOF al archivo indicado con > archivoDestino cat <<EOF > docker-compose.yml version: '3.7' services: elasticsearch: image: docker.elastic.co/elasticsearch/elasticsearch:7.15.2 container_name: elasticsearch environment: - node.name=elasticsearch - cluster.name=es-docker-cluster - bootstrap.memory_lock=true - \"ES_JAVA_OPTS=-Xms512m -Xmx512m\" - \"discovery.type=single-node\" - \"xpack.security.enabled=false\" ulimits: memlock: soft: -1 hard: -1 volumes: - esdata:/usr/share/elasticsearch/data ports: - 9200:9200 kibana: image: docker.elastic.co/kibana/kibana:7.15.2 container_name: kibana ports: - 5601:5601 environment: ELASTICSEARCH_URL: <http://elasticsearch:9200/> # URL de Elasticsearch volumes: - ./kibana.yml:/usr/share/kibana/config/kibana.yml depends_on: - elasticsearch filebeat: image: docker.elastic.co/beats/filebeat:7.15.2 container_name: filebeat user: root volumes: - ./filebeat.yml:/usr/share/filebeat/filebeat.yml:ro - /var/log:/var/log:ro depends_on: - elasticsearch logstash: image: docker.elastic.co/logstash/logstash:7.15.2 container_name: logstash volumes: - ./logstash.conf:/usr/share/logstash/pipeline/logstash.conf:ro ports: - 5044:5044 depends_on: - elasticsearch suricata: image: jasonish/suricata:latest user: root privileged: true volumes: - /var/log/suricata:/var/log/suricata - ./suricata.yaml:/etc/suricata/suricata.yaml:ro - /var/lib/suricata/rules:/var/lib/suricata/rules - /etc/suricata/classification.config:/etc/suricata/classification.config network_mode: \"host\" command: -c /etc/suricata/suricata.yaml -i $tarjetaRed volumes: esdata: driver: local networks: default: external: name: encriptadisimo EOF #Creacion filebeat - Redirije el contenido del EOF al archivo indicado con > archivoDestino cat <<EOF > filebeat.yml filebeat.inputs: - type: log enabled: true paths: - /var/log/*.log - /var/log/syslog - /var/log/nginx/*.log - /var/log/apache2/*.log - /var/log/mysql/error.log - /var/log/postgresql/*.log - /var/log/suricata/eve.json - /var/log/packetbeat/* filebeat.modules: - module: system syslog: enabled: false auth: enabled: true var.paths: [\"/var/log/auth.log\"] output.logstash: hosts: [\"logstash:5044\"] setup.kibana: host: \"kibana:5601\" fields: event.dataset: keyword EOF #Creacion logstash - Redirije el contenido del EOF al archivo indicado con > archivoDestino cat <<EOF > logstash.conf input { beats { port => 5044 } } filter { if [fileset][module] == \"system\" { if [fileset][name] == \"auth\" { grok { match => { \"message\" => [ \"%{SYSLOGTIMESTAMP:[system][auth][timestamp]} %{SYSLOGHOST:[system][auth][hostname]} sshd(?:\\[%{POSINT:[system][auth][pid]}\\])?: %{DATA:[system][auth][ssh][event]} %{DATA:[system][auth][ssh][method]} %{DATA:[system][auth][ssh][username]} %{DATA:[system][auth][ssh][ip]}(?: %{GREEDYDATA:[system][auth][ssh][data]})?\", \"%{SYSLOGTIMESTAMP:[system][auth][timestamp]} %{SYSLOGHOST:[system][auth][hostname]} sudo(?:\\[%{POSINT:[system][auth][pid]}\\])?: %{DATA:[system][auth][user]} %{DATA:[system][auth][sudo][tty]}=%{DATA:[system][auth][sudo][user]}(?:\\(%{DATA:[system][auth][sudo][runas]}\\))?: %{GREEDYDATA:[system][auth][sudo][command]}\" ] } pattern_definitions => { \"GREEDYDATA\" => \".*\" } remove_field => \"message\" } mutate { rename => { \"@timestamp\" => \"read_timestamp\" } } date { match => [ \"[system][auth][timestamp]\", \"MMM d HH:mm:ss\", \"MMM dd HH:mm:ss\" ] } geoip { source => \"[system][auth][ssh][ip]\" target => \"[system][auth][ssh][geoip]\" } if [system][auth][sudo][command] { grok { match => { \"[system][auth][sudo][command]\" => \"^ %{USER:[system][auth][sudo][run_as_user]} : TTY=%{DATA:[system][auth][sudo][tty]} ; PWD=%{DATA:[system][auth][sudo][pwd]} ; USER=%{USER:[system][auth][sudo][user]} ; COMMAND=%{GREEDYDATA:[system][auth][sudo][command]}\" } } } } } } output { elasticsearch { hosts => [\"elasticsearch:9200\"] manage_template => false index => \"filebeat\" } } EOF #Creacion suricata - Redirije el contenido del EOF al archivo indicado con > archivoDestino cat <<EOF > suricata.yaml %YAML 1.1 --- # Configuraci\u00f3n de Suricata default-log-dir: /var/log/suricata/ # Definici\u00f3n de las reglas rule-files: - /var/lib/suricata/rules/*.rules # Configuraci\u00f3n de los registros outputs: - fast: enabled: yes filename: fast.log append: yes - eve-log: enabled: yes filetype: regular filename: eve.json append: yes - syslog: enabled: yes # Configuraci\u00f3n de la detecci\u00f3n de anomal\u00edas anomaly: detection-ports: - 21 # FTP - 22 # SSH - 23 # Telnet - 25 # SMTP - 80 # HTTP # Configuraci\u00f3n de los protocolos de capa de aplicaci\u00f3n # Configuraci\u00f3n de los protocolos de capa de aplicaci\u00f3n app-layer: protocols: dcerpc: enabled: yes smb: enabled: yes ftp: enabled: yes ssh: enabled: yes smtp: enabled: yes dns: enabled: yes modbus: enabled: no http: enabled: yes tls: enabled: yes enip: enabled: yes dnp3: enabled: yes nfs: enabled: yes ntp: enabled: yes tftp: enabled: yes ikev2: enabled: no krb5: enabled: yes dhcp: enabled: yes snmp: enabled: yes sip: enabled: yes rfb: enabled: yes mqtt: enabled: yes rdp: enabled: yes http2: enabled: yes imap: enabled: yes # Configuraci\u00f3n de las interfaces af-packet: - interface: $tarjetaRed cluster-id: 99 cluster-type: cluster_flow defrag: yes # Configuraci\u00f3n de la preprocesamiento prelude: enabled: yes log-dir: /var/log/suricata/ # Configuraci\u00f3n de la extracci\u00f3n de archivos file-extraction: enabled: yes # Directorio donde se almacenan los archivos extra\u00eddos directory: /var/log/suricata/files # Establecer en 'yes' para habilitar el c\u00e1lculo autom\u00e1tico del hash MD5 del archivo # md5: yes # Configuraci\u00f3n de los registros HTTP http-log: enabled: yes filetype: regular filename: http.log append: yes extended: yes # Configuraci\u00f3n de los registros TLS tls-log: enabled: yes filetype: regular filename: tls.log append: yes extended: yes EOF #Creacion kibana - Redirije el contenido del EOF al archivo indicado con > archivoDestino cat <<EOF > kibana.yml elasticsearch.hosts: [\"http://elasticsearch:9200/\"] xpack.encryptedSavedObjects.encryptionKey: \"andreqwerqwerqwerqwerqwerqwerqwerqwerqwer\" server.name: kibana server.host: \"0\" EOF #Permisos sudo chown root:root filebeat.yml sudo chmod a+r filebeat.yml sudo chmod go-w filebeat.yml #Git clone de suricata git clone https://github.com/OISF/suricata.git # Reglas de Suricata y permisos de suricata sudo mkdir /var/lib/suricata sudo mkdir /var/lib/suricata/rules sudo mkdir /etc/suricata sudo mv suricata/etc/reference.config /etc/suricata/ sudo mv suricata/etc/classification.config /etc/suricata/ sudo chmod 777 -R /etc/suricata/ sudo mv suricata/rules/* /var/lib/suricata/rules/ sudo chmod 777 -R /var/lib/suricata/ # Red Encriptada de Docker sudo docker swarm init sudo docker network create --opt encrypted --attachable --driver overlay encriptadisimo #Levantar el servicio sudo docker-compose up -d echo \"SIEM montado correctamente\" echo \"Para entrar en kibana --> http://localhost:5601\"","title":"GITHUB"},{"location":"Instalaci%C3%B3n/git/#github","text":"","title":"GITHUB"},{"location":"Instalaci%C3%B3n/git/#documentacion-del-proyecto","text":"Link git proyecto: https://github.com/rodrigochavezlava/ProyectoSIEM Clonar git del script: $ git clone https://github.com/rodrigochavezlava/ProyectoSIEM/blob/main/SIEMProyecto.sh","title":"Documentaci\u00f3n del proyecto"},{"location":"Instalaci%C3%B3n/git/#script-del-proyecto","text":"Recordemos que la idea de este script es ejecutarlo en nuestra m\u00e1quina para tener un SIEM completamente funcional con tan solo un comando. Todo esto se consigue mediante la uni\u00f3n de diferentes servicios a trav\u00e9s de contenedores. #!/bin/bash # Solicitar al usuario que ingrese un valor echo \"Ingresa el nombre de la tarjeta de red que desees analizar:\" read tarjetaRed echo \"Escoge la contrase\u00f1a de tu encriptaci\u00f3n de red | min: 32 caracteres\" read claveEncriptacionRed #Calcula el numero de caracteres de la contrase\u00f1a con el # longitud = ${# claveEncriptacionRed } echo \"La longitud de la contrase\u00f1a es: $longitud caracteres.\" #Compara longitud en caso de ser menor de 32 se para if [ $longitud -ge 32 ] ; then echo \"La contrase\u00f1a tiene 32 caracteres.\" else echo \"La contrase\u00f1a no tiene 32 caracteres, SALIENDO.\" exit fi #Inicio sudo apt-get update -y #Paquetes para uso de repositorios seguros HTTPS sudo apt-get install -y apt-transport-https ca-certificates curl gnupg lsb-release #Claves GPG y volcarlas en /usr/share/keyrings curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg #A\u00f1adir la direccion de los repositorios al sistema echo \"deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu $( lsb_release -cs ) stable\" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null #Actualizar el repositorio sudo apt-get update -y #Instalar Docker sudo apt-get install -y docker-ce docker-ce-cli containerd.io #Descargar Docker Compose sudo curl -L \"https://github.com/docker/compose/releases/download/1.29.2/docker-compose- $( uname -s ) - $( uname -m ) \" -o /usr/local/bin/docker-compose #Dar permisos para ejecutar al Docker Compose sudo chmod +x /usr/local/bin/docker-compose #Creacion docker compose - Redirije el contenido del EOF al archivo indicado con > archivoDestino cat <<EOF > docker-compose.yml version: '3.7' services: elasticsearch: image: docker.elastic.co/elasticsearch/elasticsearch:7.15.2 container_name: elasticsearch environment: - node.name=elasticsearch - cluster.name=es-docker-cluster - bootstrap.memory_lock=true - \"ES_JAVA_OPTS=-Xms512m -Xmx512m\" - \"discovery.type=single-node\" - \"xpack.security.enabled=false\" ulimits: memlock: soft: -1 hard: -1 volumes: - esdata:/usr/share/elasticsearch/data ports: - 9200:9200 kibana: image: docker.elastic.co/kibana/kibana:7.15.2 container_name: kibana ports: - 5601:5601 environment: ELASTICSEARCH_URL: <http://elasticsearch:9200/> # URL de Elasticsearch volumes: - ./kibana.yml:/usr/share/kibana/config/kibana.yml depends_on: - elasticsearch filebeat: image: docker.elastic.co/beats/filebeat:7.15.2 container_name: filebeat user: root volumes: - ./filebeat.yml:/usr/share/filebeat/filebeat.yml:ro - /var/log:/var/log:ro depends_on: - elasticsearch logstash: image: docker.elastic.co/logstash/logstash:7.15.2 container_name: logstash volumes: - ./logstash.conf:/usr/share/logstash/pipeline/logstash.conf:ro ports: - 5044:5044 depends_on: - elasticsearch suricata: image: jasonish/suricata:latest user: root privileged: true volumes: - /var/log/suricata:/var/log/suricata - ./suricata.yaml:/etc/suricata/suricata.yaml:ro - /var/lib/suricata/rules:/var/lib/suricata/rules - /etc/suricata/classification.config:/etc/suricata/classification.config network_mode: \"host\" command: -c /etc/suricata/suricata.yaml -i $tarjetaRed volumes: esdata: driver: local networks: default: external: name: encriptadisimo EOF #Creacion filebeat - Redirije el contenido del EOF al archivo indicado con > archivoDestino cat <<EOF > filebeat.yml filebeat.inputs: - type: log enabled: true paths: - /var/log/*.log - /var/log/syslog - /var/log/nginx/*.log - /var/log/apache2/*.log - /var/log/mysql/error.log - /var/log/postgresql/*.log - /var/log/suricata/eve.json - /var/log/packetbeat/* filebeat.modules: - module: system syslog: enabled: false auth: enabled: true var.paths: [\"/var/log/auth.log\"] output.logstash: hosts: [\"logstash:5044\"] setup.kibana: host: \"kibana:5601\" fields: event.dataset: keyword EOF #Creacion logstash - Redirije el contenido del EOF al archivo indicado con > archivoDestino cat <<EOF > logstash.conf input { beats { port => 5044 } } filter { if [fileset][module] == \"system\" { if [fileset][name] == \"auth\" { grok { match => { \"message\" => [ \"%{SYSLOGTIMESTAMP:[system][auth][timestamp]} %{SYSLOGHOST:[system][auth][hostname]} sshd(?:\\[%{POSINT:[system][auth][pid]}\\])?: %{DATA:[system][auth][ssh][event]} %{DATA:[system][auth][ssh][method]} %{DATA:[system][auth][ssh][username]} %{DATA:[system][auth][ssh][ip]}(?: %{GREEDYDATA:[system][auth][ssh][data]})?\", \"%{SYSLOGTIMESTAMP:[system][auth][timestamp]} %{SYSLOGHOST:[system][auth][hostname]} sudo(?:\\[%{POSINT:[system][auth][pid]}\\])?: %{DATA:[system][auth][user]} %{DATA:[system][auth][sudo][tty]}=%{DATA:[system][auth][sudo][user]}(?:\\(%{DATA:[system][auth][sudo][runas]}\\))?: %{GREEDYDATA:[system][auth][sudo][command]}\" ] } pattern_definitions => { \"GREEDYDATA\" => \".*\" } remove_field => \"message\" } mutate { rename => { \"@timestamp\" => \"read_timestamp\" } } date { match => [ \"[system][auth][timestamp]\", \"MMM d HH:mm:ss\", \"MMM dd HH:mm:ss\" ] } geoip { source => \"[system][auth][ssh][ip]\" target => \"[system][auth][ssh][geoip]\" } if [system][auth][sudo][command] { grok { match => { \"[system][auth][sudo][command]\" => \"^ %{USER:[system][auth][sudo][run_as_user]} : TTY=%{DATA:[system][auth][sudo][tty]} ; PWD=%{DATA:[system][auth][sudo][pwd]} ; USER=%{USER:[system][auth][sudo][user]} ; COMMAND=%{GREEDYDATA:[system][auth][sudo][command]}\" } } } } } } output { elasticsearch { hosts => [\"elasticsearch:9200\"] manage_template => false index => \"filebeat\" } } EOF #Creacion suricata - Redirije el contenido del EOF al archivo indicado con > archivoDestino cat <<EOF > suricata.yaml %YAML 1.1 --- # Configuraci\u00f3n de Suricata default-log-dir: /var/log/suricata/ # Definici\u00f3n de las reglas rule-files: - /var/lib/suricata/rules/*.rules # Configuraci\u00f3n de los registros outputs: - fast: enabled: yes filename: fast.log append: yes - eve-log: enabled: yes filetype: regular filename: eve.json append: yes - syslog: enabled: yes # Configuraci\u00f3n de la detecci\u00f3n de anomal\u00edas anomaly: detection-ports: - 21 # FTP - 22 # SSH - 23 # Telnet - 25 # SMTP - 80 # HTTP # Configuraci\u00f3n de los protocolos de capa de aplicaci\u00f3n # Configuraci\u00f3n de los protocolos de capa de aplicaci\u00f3n app-layer: protocols: dcerpc: enabled: yes smb: enabled: yes ftp: enabled: yes ssh: enabled: yes smtp: enabled: yes dns: enabled: yes modbus: enabled: no http: enabled: yes tls: enabled: yes enip: enabled: yes dnp3: enabled: yes nfs: enabled: yes ntp: enabled: yes tftp: enabled: yes ikev2: enabled: no krb5: enabled: yes dhcp: enabled: yes snmp: enabled: yes sip: enabled: yes rfb: enabled: yes mqtt: enabled: yes rdp: enabled: yes http2: enabled: yes imap: enabled: yes # Configuraci\u00f3n de las interfaces af-packet: - interface: $tarjetaRed cluster-id: 99 cluster-type: cluster_flow defrag: yes # Configuraci\u00f3n de la preprocesamiento prelude: enabled: yes log-dir: /var/log/suricata/ # Configuraci\u00f3n de la extracci\u00f3n de archivos file-extraction: enabled: yes # Directorio donde se almacenan los archivos extra\u00eddos directory: /var/log/suricata/files # Establecer en 'yes' para habilitar el c\u00e1lculo autom\u00e1tico del hash MD5 del archivo # md5: yes # Configuraci\u00f3n de los registros HTTP http-log: enabled: yes filetype: regular filename: http.log append: yes extended: yes # Configuraci\u00f3n de los registros TLS tls-log: enabled: yes filetype: regular filename: tls.log append: yes extended: yes EOF #Creacion kibana - Redirije el contenido del EOF al archivo indicado con > archivoDestino cat <<EOF > kibana.yml elasticsearch.hosts: [\"http://elasticsearch:9200/\"] xpack.encryptedSavedObjects.encryptionKey: \"andreqwerqwerqwerqwerqwerqwerqwerqwerqwer\" server.name: kibana server.host: \"0\" EOF #Permisos sudo chown root:root filebeat.yml sudo chmod a+r filebeat.yml sudo chmod go-w filebeat.yml #Git clone de suricata git clone https://github.com/OISF/suricata.git # Reglas de Suricata y permisos de suricata sudo mkdir /var/lib/suricata sudo mkdir /var/lib/suricata/rules sudo mkdir /etc/suricata sudo mv suricata/etc/reference.config /etc/suricata/ sudo mv suricata/etc/classification.config /etc/suricata/ sudo chmod 777 -R /etc/suricata/ sudo mv suricata/rules/* /var/lib/suricata/rules/ sudo chmod 777 -R /var/lib/suricata/ # Red Encriptada de Docker sudo docker swarm init sudo docker network create --opt encrypted --attachable --driver overlay encriptadisimo #Levantar el servicio sudo docker-compose up -d echo \"SIEM montado correctamente\" echo \"Para entrar en kibana --> http://localhost:5601\"","title":"Script del proyecto"},{"location":"Introducci%C3%B3n/Funcionamiento-del-SIEM/","text":"Funcionamiento del SIEM \u00b6 Suricata monitorea el tr\u00e1fico en busca de actividades maliciosas y genera eventos de seguridad. Estos eventos son capturados por Filebeat, que a su vez recoge todos los logs del sistema. Esto est\u00e1 configurado en los archivos que veremos m\u00e1s adelante. Los logs, tanto generados por Filebeat como por Suricata, son enviados a Logstash para su procesamiento. Logstash realiza tareas de filtrado, transformaci\u00f3n y enriquecimiento de los datos, prepar\u00e1ndolos para su almacenamiento y an\u00e1lisis. Los eventos procesados son almacenados e indexados en Elasticsearch, una base de datos distribuida en tiempo real. Kibana interact\u00faa con Elasticsearch para visualizar y explorar los datos almacenados, permitiendo la creaci\u00f3n de cuadros de datos, gr\u00e1ficos y paneles de control. Tecnolog\u00edas Implementadas \u00b6 SIEM: El Security Information and Event Management (SIEM) es una tecnolog\u00eda esencial en ciberseguridad que recopila y analiza datos y registros en tiempo real. Proporciona una visi\u00f3n completa de las actividades y eventos de seguridad en una red, permitiendo detectar y responder r\u00e1pidamente a posibles amenazas y ataques. Docker Compose: Docker Compose es una herramienta poderosa que simplifica la gesti\u00f3n de aplicaciones compuestas por m\u00faltiples contenedores. Permite definir la configuraci\u00f3n de la aplicaci\u00f3n en un archivo YAML y ejecutarlo f\u00e1cilmente para crear y desplegar todos los contenedores con la configuraci\u00f3n predefinida. Suricata: Suricata es un sistema de prevenci\u00f3n de intrusiones en red (IPS) y motor de detecci\u00f3n de amenazas (IDS) de c\u00f3digo abierto. Su funci\u00f3n es monitorear y analizar el tr\u00e1fico de red en tiempo real, buscando actividades maliciosas y an\u00f3malas. Con reglas y firmas, Suricata puede detectar y prevenir ataques, proporcionando una capa adicional de seguridad en la infraestructura de red. Filebeat: Filebeat es un agente ligero dise\u00f1ado para recopilar, enviar y procesar logs y datos desde diferentes archivos y ubicaciones. Al integrarse con la pila ELK, Filebeat permite realizar un seguimiento en tiempo real de los cambios en los archivos y enviar los datos a Elasticsearch o Logstash para su almacenamiento y an\u00e1lisis, facilitando la gesti\u00f3n y recolecci\u00f3n de logs en entornos distribuidos. Logstash: Logstash es una herramienta flexible y potente de procesamiento y enriquecimiento de datos. Act\u00faa como un canalizador de datos, extrayendo informaci\u00f3n de diversas fuentes, aplicando filtros y transformaciones para mejorar la estructura y calidad de los datos. Logstash se integra con Elasticsearch y otras herramientas, desempe\u00f1ando un papel clave en el flujo de datos de un sistema de registro y an\u00e1lisis de logs. Elasticsearch: Elasticsearch es un motor de b\u00fasqueda y an\u00e1lisis de datos distribuido y de c\u00f3digo abierto. Ofrece una soluci\u00f3n escalable para almacenar, indexar y buscar grandes vol\u00famenes de datos en tiempo real. Con su modelo de b\u00fasqueda basado en documentos, Elasticsearch permite realizar consultas complejas y avanzadas sobre los datos indexados, y se integra con otras herramientas de la pila ELK para el an\u00e1lisis y la visualizaci\u00f3n de datos. Kibana: Kibana es una plataforma intuitiva y potente de visualizaci\u00f3n y an\u00e1lisis de datos dise\u00f1ada para trabajar con Elasticsearch. Permite explorar, visualizar y compartir datos almacenados en Elasticsearch de manera interactiva. Con Kibana, se pueden crear gr\u00e1ficos, tablas y paneles personalizados, realizar b\u00fasquedas y aplicar filtros en tiempo real, facilitando el monitoreo, an\u00e1lisis y visualizaci\u00f3n de datos en entornos de aplicaciones y sistemas.","title":"Funcionamiento del SIEM"},{"location":"Introducci%C3%B3n/Funcionamiento-del-SIEM/#funcionamiento-del-siem","text":"Suricata monitorea el tr\u00e1fico en busca de actividades maliciosas y genera eventos de seguridad. Estos eventos son capturados por Filebeat, que a su vez recoge todos los logs del sistema. Esto est\u00e1 configurado en los archivos que veremos m\u00e1s adelante. Los logs, tanto generados por Filebeat como por Suricata, son enviados a Logstash para su procesamiento. Logstash realiza tareas de filtrado, transformaci\u00f3n y enriquecimiento de los datos, prepar\u00e1ndolos para su almacenamiento y an\u00e1lisis. Los eventos procesados son almacenados e indexados en Elasticsearch, una base de datos distribuida en tiempo real. Kibana interact\u00faa con Elasticsearch para visualizar y explorar los datos almacenados, permitiendo la creaci\u00f3n de cuadros de datos, gr\u00e1ficos y paneles de control.","title":"Funcionamiento del SIEM"},{"location":"Introducci%C3%B3n/Funcionamiento-del-SIEM/#tecnologias-implementadas","text":"SIEM: El Security Information and Event Management (SIEM) es una tecnolog\u00eda esencial en ciberseguridad que recopila y analiza datos y registros en tiempo real. Proporciona una visi\u00f3n completa de las actividades y eventos de seguridad en una red, permitiendo detectar y responder r\u00e1pidamente a posibles amenazas y ataques. Docker Compose: Docker Compose es una herramienta poderosa que simplifica la gesti\u00f3n de aplicaciones compuestas por m\u00faltiples contenedores. Permite definir la configuraci\u00f3n de la aplicaci\u00f3n en un archivo YAML y ejecutarlo f\u00e1cilmente para crear y desplegar todos los contenedores con la configuraci\u00f3n predefinida. Suricata: Suricata es un sistema de prevenci\u00f3n de intrusiones en red (IPS) y motor de detecci\u00f3n de amenazas (IDS) de c\u00f3digo abierto. Su funci\u00f3n es monitorear y analizar el tr\u00e1fico de red en tiempo real, buscando actividades maliciosas y an\u00f3malas. Con reglas y firmas, Suricata puede detectar y prevenir ataques, proporcionando una capa adicional de seguridad en la infraestructura de red. Filebeat: Filebeat es un agente ligero dise\u00f1ado para recopilar, enviar y procesar logs y datos desde diferentes archivos y ubicaciones. Al integrarse con la pila ELK, Filebeat permite realizar un seguimiento en tiempo real de los cambios en los archivos y enviar los datos a Elasticsearch o Logstash para su almacenamiento y an\u00e1lisis, facilitando la gesti\u00f3n y recolecci\u00f3n de logs en entornos distribuidos. Logstash: Logstash es una herramienta flexible y potente de procesamiento y enriquecimiento de datos. Act\u00faa como un canalizador de datos, extrayendo informaci\u00f3n de diversas fuentes, aplicando filtros y transformaciones para mejorar la estructura y calidad de los datos. Logstash se integra con Elasticsearch y otras herramientas, desempe\u00f1ando un papel clave en el flujo de datos de un sistema de registro y an\u00e1lisis de logs. Elasticsearch: Elasticsearch es un motor de b\u00fasqueda y an\u00e1lisis de datos distribuido y de c\u00f3digo abierto. Ofrece una soluci\u00f3n escalable para almacenar, indexar y buscar grandes vol\u00famenes de datos en tiempo real. Con su modelo de b\u00fasqueda basado en documentos, Elasticsearch permite realizar consultas complejas y avanzadas sobre los datos indexados, y se integra con otras herramientas de la pila ELK para el an\u00e1lisis y la visualizaci\u00f3n de datos. Kibana: Kibana es una plataforma intuitiva y potente de visualizaci\u00f3n y an\u00e1lisis de datos dise\u00f1ada para trabajar con Elasticsearch. Permite explorar, visualizar y compartir datos almacenados en Elasticsearch de manera interactiva. Con Kibana, se pueden crear gr\u00e1ficos, tablas y paneles personalizados, realizar b\u00fasquedas y aplicar filtros en tiempo real, facilitando el monitoreo, an\u00e1lisis y visualizaci\u00f3n de datos en entornos de aplicaciones y sistemas.","title":"Tecnolog\u00edas Implementadas"},{"location":"Introducci%C3%B3n/Introducci%C3%B3n/","text":"Introducci\u00f3n \u00b6 El proyecto consiste en llevar a cabo la instalaci\u00f3n de un SIEM mediante la ejecuci\u00f3n de un solo script. Esto se conseguir\u00e1 mediante Docker Compose, ya que de esta forma crearemos en un solo archivo un contenedor para cada servicio necesario. En el mismo archivo se configurar\u00e1n las conexiones entre s\u00ed de los softwares, as\u00ed como la ruta de utilidad y cualquier tipo de configuraci\u00f3n necesaria de cada software aislado. Por esto, el proyecto constar\u00e1 de un archivo Docker Compose con lo mencionado anteriormente y diferentes archivos yml que configuran particularidades de los servicios. Adem\u00e1s, durante el proceso se har\u00e1 uso de distintos archivos de configuraci\u00f3n .rule para Suricata. Todo esto con la finalidad de facilitar y automatizar el proceso de instalaci\u00f3n de un SIEM completamente funcional y personalizable, con todas las facilidades posibles para el usuario final, incluyendo adem\u00e1s un manual de usuario para que sea f\u00e1cil el uso y entendimiento del script.","title":"Introducci\u00f3n"},{"location":"Introducci%C3%B3n/Introducci%C3%B3n/#introduccion","text":"El proyecto consiste en llevar a cabo la instalaci\u00f3n de un SIEM mediante la ejecuci\u00f3n de un solo script. Esto se conseguir\u00e1 mediante Docker Compose, ya que de esta forma crearemos en un solo archivo un contenedor para cada servicio necesario. En el mismo archivo se configurar\u00e1n las conexiones entre s\u00ed de los softwares, as\u00ed como la ruta de utilidad y cualquier tipo de configuraci\u00f3n necesaria de cada software aislado. Por esto, el proyecto constar\u00e1 de un archivo Docker Compose con lo mencionado anteriormente y diferentes archivos yml que configuran particularidades de los servicios. Adem\u00e1s, durante el proceso se har\u00e1 uso de distintos archivos de configuraci\u00f3n .rule para Suricata. Todo esto con la finalidad de facilitar y automatizar el proceso de instalaci\u00f3n de un SIEM completamente funcional y personalizable, con todas las facilidades posibles para el usuario final, incluyendo adem\u00e1s un manual de usuario para que sea f\u00e1cil el uso y entendimiento del script.","title":"Introducci\u00f3n"}]}